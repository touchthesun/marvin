<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Wiki Page</title>
    <meta name="description" content="A sample wiki page for testing content extraction">
</head>
<body>
    <header>
        <h1>Neural Networks</h1>
        <div class="metadata">
            <span>Last updated: January 15, 2023</span>
            <span>Category: Machine Learning</span>
        </div>
    </header>
    
    <nav>
        <ul>
            <li><a href="#introduction">Introduction</a></li>
            <li><a href="#history">History</a></li>
            <li><a href="#types">Types of Neural Networks</a></li>
            <li><a href="#applications">Applications</a></li>
            <li><a href="#references">References</a></li>
        </ul>
    </nav>
    
    <main>
        <section id="introduction">
            <h2>Introduction to Neural Networks</h2>
            <p>
                Neural networks are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns. 
                They interpret sensory data through a kind of machine perception, labeling or clustering raw input.
            </p>
            <p>
                The patterns they recognize are numerical, contained in vectors, into which all real-world data, 
                be it images, sound, text or time series, must be translated.
            </p>
        </section>
        
        <section id="history">
            <h2>History of Neural Networks</h2>
            <p>
                The history of neural networks begins with the first computational model of a neuron proposed by Warren McCulloch and Walter Pitts in 1943.
                This was followed by the development of the perceptron by Frank Rosenblatt in 1958.
            </p>
            <p>
                After a period of reduced interest (known as the "AI winter"), neural networks saw a resurgence in the 2000s
                with the development of deep learning techniques and increased computational power.
            </p>
        </section>
        
        <section id="types">
            <h2>Types of Neural Networks</h2>
            <ul>
                <li><strong>Feedforward Neural Networks</strong>: The simplest type of artificial neural network. Data moves in only one direction, forward, from input nodes, through hidden layers, to output nodes.</li>
                <li><strong>Convolutional Neural Networks (CNNs)</strong>: Primarily used for image processing, CNNs use convolutional layers to detect patterns in spatial data.</li>
                <li><strong>Recurrent Neural Networks (RNNs)</strong>: Used for sequential data such as time series or natural language. RNNs have connections that form directed cycles.</li>
                <li><strong>Long Short-Term Memory Networks (LSTMs)</strong>: A special kind of RNN capable of learning long-term dependencies.</li>
                <li><strong>Generative Adversarial Networks (GANs)</strong>: Consist of two networks, a generator and a discriminator, that compete with each other to generate new, synthetic instances of data.</li>
            </ul>
        </section>
        
        <section id="applications">
            <h2>Applications</h2>
            <p>Neural networks have been applied to various domains:</p>
            <table>
                <thead>
                    <tr>
                        <th>Domain</th>
                        <th>Applications</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Computer Vision</td>
                        <td>Image recognition, object detection, facial recognition</td>
                    </tr>
                    <tr>
                        <td>Natural Language Processing</td>
                        <td>Translation, sentiment analysis, chatbots</td>
                    </tr>
                    <tr>
                        <td>Time Series Analysis</td>
                        <td>Stock market prediction, weather forecasting</td>
                    </tr>
                    <tr>
                        <td>Medicine</td>
                        <td>Disease diagnosis, drug discovery</td>
                    </tr>
                </tbody>
            </table>
        </section>
        
        <section id="references">
            <h2>References</h2>
            <ol>
                <li>McCulloch, W. S., & Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. <em>The bulletin of mathematical biophysics</em>, 5(4), 115-133.</li>
                <li>Rosenblatt, F. (1958). The perceptron: a probabilistic model for information storage and organization in the brain. <em>Psychological review</em>, 65(6), 386.</li>
                <li>LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. <em>Nature</em>, 521(7553), 436-444.</li>
                <li>Goodfellow, I., Bengio, Y., & Courville, A. (2016). <em>Deep learning</em>. MIT press.</li>
            </ol>
        </section>
    </main>
    
    <footer>
        <p>This is a sample wiki page created for testing Marvin's content analysis pipeline.</p>
    </footer>
</body>
</html>